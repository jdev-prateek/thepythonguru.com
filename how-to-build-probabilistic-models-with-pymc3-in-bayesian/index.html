<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <title>How to build probabilistic models with PyMC3 in Bayesian - ThePythonGuru.com</title>

    
    



    <meta name="description" content="The basic idea of probabilistic programming with PyMC3 is to specify models using code and then solve them in an automatic way. Probabilistic program…"/>



    <link rel="canonical" href="index.html">


<meta property="og:locale" content="en_US" />
<meta property="og:type" content="article" />
<meta property="og:title" content="How to build probabilistic models with PyMC3 in Bayesian" />

    <meta property="og:description" content="The basic idea of probabilistic programming with PyMC3 is to specify models using code and then solve them in an automatic way. Probabilistic program…" />


<meta property="og:url" content="https://thepythonguru.com/how-to-build-probabilistic-models-with-pymc3-in-bayesian/" />
<meta property="og:site_name" content="thepythonguru.com" />


<meta property="article:publisher" content="https://www.facebook.com/thepythonguru" />



<meta name="twitter:card" content="summary_large_image" />

    <meta name="twitter:description" content="The basic idea of probabilistic programming with PyMC3 is to specify models using code and then solve them in an automatic way. Probabilistic program…" />


<meta name="twitter:title" content="How to build probabilistic models with PyMC3 in Bayesian" />
<meta name="twitter:site" content="@thepythonguru" />

<meta name="twitter:creator" content="@thepythonguru" />




    
    
    


    
    
    


    <link rel="alternate" type="application/rss+xml" title="RSS" href="../feed.xml/index.html">
    <link href="https://fonts.googleapis.com/css?family=Open+Sans" rel="stylesheet">
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css">
    <link rel="icon" href="../static/wiki/favicon.png" sizes="32x32" />

    <link rel="stylesheet" href="../static/CACHE/css/output.6be9976864ee.css" type="text/css" />

    <!-- HTML5 Shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
    <!--[if lt IE 9]>
    <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
    <script src="https://oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script>
    <![endif]-->

    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-39121661-7"></script>
    <script>
        window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());

        gtag('config', 'UA-39121661-7');
    </script>


</head>
<body>

<!-- Navigation -->
<nav class="navbar navbar-default navbar-inverse" >
    <div class="container">
        <!-- Brand and toggle get grouped for better mobile display -->
        <div class="navbar-header">
            <button type="button" class="navbar-toggle" data-toggle="collapse" data-target="#bs-example-navbar-collapse-1">
                <span class="sr-only">Toggle navigation</span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
            </button>
            <a class="navbar-brand" href="../index.html">ThePythonGuru</a>
        </div>
        <!-- Collect the nav links, forms, and other content for toggling -->
        <div class="collapse navbar-collapse " id="bs-example-navbar-collapse-1">
            <ul class="nav navbar-nav">
                

                <li >
                    <a href="../index.html">Start Here</a>
                </li>
                <li >
                    <a href="../blog/index.html">Blog</a>
                </li>
                
                
                
                <li >
                    <a href="../contact-us/index.html">Contact</a>
                </li>
                <li >
                    <a href="../write-for-us/index.html">Write For Us</a>
                </li>
                <li class="dropdown">
                    <a href="index.html#" class="dropdown-toggle" data-toggle="dropdown" role="button"
                       aria-haspopup="true" aria-expanded="false">Tools <span class="caret"></span>
                    </a>
                    <ul class="dropdown-menu">
                        <li><a href="../tools/pygments-demo/index.html">Pygments Demo</a></li>
                    </ul>
                </li>




                
                
                
                
                
                
                
                
                
            </ul>

            
            
            
            
            
            
            
            

        </div>



        <!-- /.navbar-collapse -->
    </div>
    <!-- /.container -->
</nav>

<div class="container">

    

    

    <div class="row">

        
        <div class="main">
            <div  class="col-lg-8 col-md-8 col-sm-12">
                

    


    
        

<ol class="breadcrumb">

    <li><a href="../index.html">Home</a></li>

    
        

        
            <li><a href="../blog/index.html">Blog</a></li>
        

        
            <li class="active">How to build probabilistic models with PyMC3 in Bayesian</li>
        
    

</ol>


    



<p class="advert">
    (Sponsors) Get started learning Python with <a rel="sponsored noopener" target="_blank" href="https://www.datacamp.com/?utm_source=thepythonguru&utm_campaign=thepythonguru_tutorials">DataCamp's</a>
    free <a rel="sponsored noopener" target="_blank" href="https://www.datacamp.com/courses/intro-to-python-for-data-science/?utm_source=thepythonguru&utm_campaign=thepythonguru_tutorials">Intro to Python tutorial</a>.

    Learn Data Science by completing interactive coding challenges and watching videos by expert instructors.
    <a rel="sponsored noopener" target="_blank" href="https://www.datacamp.com/courses/intro-to-python-for-data-science/?utm_source=thepythonguru&utm_campaign=thepythonguru_tutorials">Start Now!</a>
</p>
<hr>

<h1>How to build probabilistic models with PyMC3 in Bayesian</h1>




    <p><i class="fa fa-clock-o" aria-hidden="true"></i>
        Updated on Jan 07, 2020
    </p>


<hr>



<p>The basic idea of probabilistic programming with PyMC3 is to specify models using code and then solve them in an automatic way. Probabilistic programming offers an effective way to build and solve complex models and allows us to focus more on model design, evaluation, and interpretation, and less on mathematical or computational details.</p><p>This post is taken from the book <a href="https://www.packtpub.com/big-data-and-business-intelligence/bayesian-analysis-python-second-edition?utm_source=pythonguru&amp;utm_medium=referral&amp;utm_campaign=Outreach_PTN" rel="nofollow" >Bayesian Analysis with Python</a> by Packt Publishing written by author Osvaldo Martin. This book discusses PyMC3, a very flexible <a href="https://www.packtpub.com/tech/python" rel="nofollow" >Python</a> library for probabilistic programming, as well as ArviZ, a new Python library that will help us interpret the results of probabilistic models.</p><span id="probabilistic-programming" class="anchor-target"></span><h2 class="heading">Probabilistic programming <a class="header-link" href="index.html#probabilistic-programming">#</a></h2><hr>
<p>Bayesian statistics is conceptually very simple; we have the knowns and the unknowns; we use <a href="https://hub.packtpub.com/implementing-3-naive-bayes-classifiers-in-scikit-learn/" rel="nofollow" >Bayes&#39; theorem</a> to condition the latter on the former. If we are lucky, this process will reduce the uncertainty about the unknowns. Generally, we refer to the knowns as data and treat it like a constant and the unknowns as parameters and treat them as probability distributions. In more formal terms, we assign probability distributions to unknown quantities. Then, we use Bayes&#39; theorem to transform the prior probability distribution into a posterior distribution.</p><p>\begin{gather*}
p(\theta)
\end{gather*}</p><p>\begin{gather*}
p(\theta | y)
\end{gather*}</p><p>Although conceptually simple, fully probabilistic models often lead to analytically intractable expressions. For many years, this was a real problem and was probably one of the main issues that hindered the wide adoption of Bayesian methods.</p><p>The arrival of the computational era and the development of numerical methods that, at least in principle, can be used to solve any inference problem, has dramatically transformed the Bayesian data analysis practice. The possibility of automating the inference process has led to the development of <strong>probabilistic programming languages (PPL)</strong>, which allows for a clear separation between model creation and inference.</p><span id="pymc3-primer" class="anchor-target"></span><h2 class="heading">PyMC3 primer <a class="header-link" href="index.html#pymc3-primer">#</a></h2><hr>
<p>PyMC3 is a <a href="https://www.packtpub.com/tech/python" rel="nofollow" >Python</a> library for probabilistic programming. The last version at the moment of writing is 3.6. PyMC3 provides a very simple and intuitive syntax that is easy to read and that is close to the syntax used in the statistical literature to describe probabilistic models. PyMC3&#39;s base code is written using <a href="https://hub.packtpub.com/core-python-team-confirms-sunsetting-python-2-on-january-1-2020/" rel="nofollow" >Python</a>, and the computationally demanding parts are written using NumPy and Theano.</p><p><a href="https://hub.packtpub.com/some-basic-concepts-theano/" rel="nofollow" >Theano</a> is a Python library that was originally developed for deep learning and allows us to define, optimize, and evaluate mathematical expressions involving multidimensional arrays efficiently. The main reason PyMC3 uses Theano is because some of the sampling methods, such as NUTS, need gradients to be computed, and Theano knows how to compute gradients using what is known as automatic differentiation.</p><span id="flipping-coins-the-pymc3-way" class="anchor-target"></span><h2 class="heading">Flipping coins the PyMC3 way <a class="header-link" href="index.html#flipping-coins-the-pymc3-way">#</a></h2><hr>
<p>Since we are generating the data, we know the true value of \(\theta\), called <code>theta_real</code>, in the following code. Of course, for a real dataset, we will not have this knowledge:</p><div class="codeblock language-python"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre>1
2
3
4</pre></div></td><td class="code"><div class="highlight"><pre><span></span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">123</span><span class="p">)</span>
<span class="n">trials</span> <span class="o">=</span> <span class="mi">4</span>
<span class="n">theta_real</span> <span class="o">=</span> <span class="mf">0.35</span> <span class="c1"># unknown value in a real experiment</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">bernoulli</span><span class="o">.</span><span class="n">rvs</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="n">theta_real</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">trials</span><span class="p">)</span>
</pre></div>
</td></tr></table></div><span id="model-specification" class="anchor-target"></span><h2 class="heading">Model specification <a class="header-link" href="index.html#model-specification">#</a></h2><hr>
<p>Now that we have the data, we need to specify the model. Remember that this is done by specifying the likelihood and the prior using probability distributions. For the likelihood, we will use the binomial distribution with \(n==1\) and \(p==\theta\) , and for the prior, a beta distribution with the parameters \(\alpha==\beta==1\).</p><p>A beta distribution with such parameters is equivalent to a uniform distribution in the interval [0, 1]. We can write the model using mathematical notation:</p><p>\begin{gather*}
\theta \sim Beta(\alpha,\beta) \\
y \sim Bern(n=1,p=0)
\end{gather*}</p><p>This statistical model has an almost one-to-one translation to PyMC3:</p><div class="codeblock language-python"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre>1
2
3
4</pre></div></td><td class="code"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">pm</span><span class="o">.</span><span class="n">Model</span><span class="p">()</span> <span class="k">as</span> <span class="n">our_first_model</span><span class="p">:</span>
    <span class="err">θ</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Beta</span><span class="p">(</span><span class="s1">&#39;θ&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">1.</span><span class="p">,</span> <span class="n">beta</span><span class="o">=</span><span class="mf">1.</span><span class="p">)</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Bernoulli</span><span class="p">(</span><span class="s1">&#39;y&#39;</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="err">θ</span><span class="p">,</span> <span class="n">observed</span><span class="o">=</span><span class="n">data</span><span class="p">)</span>
    <span class="n">trace</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="mi">1000</span><span class="p">,</span> <span class="n">random_seed</span><span class="o">=</span><span class="mi">123</span><span class="p">)</span>
</pre></div>
</td></tr></table></div><p>The first line of the code creates a container for our model. Everything inside the <code>with-block</code> will be automatically added to <code>our_first_model</code>. You can think of this as syntactic sugar to ease model specification as we do not need to manually assign variables to the model. The second line specifies the prior. As you can see, the syntax follows the mathematical notation closely.</p><p>The third line specifies the likelihood. The syntax is almost the same as for the prior, except that we pass the data using the <code>observed</code> argument. This is the way in which we tell PyMC3 that we want to condition for the unknown on the knowns (<code>data</code>). The observed values can be passed as a <a href="https://www.packtpub.com/tech/python" rel="nofollow" >Python</a> list, a tuple, a NumPy array, or a pandas DataFrame.</p><span id="pushing-the-inference-button" class="anchor-target"></span><h2 class="heading">Pushing the inference button <a class="header-link" href="index.html#pushing-the-inference-button">#</a></h2><hr>
<p>The last line is the <strong>inference button</strong>. We are asking for 1,000 samples from the posterior and will store them in the <code>trace</code> object. Behind this innocent line, PyMC3 has hundreds of <strong>oompa loompas</strong> singing and baking a delicious Bayesian inference just for you! Well, not exactly, but PyMC3 is automating a lot of tasks. If you run the code, you will get a message like this:</p><div class="codeblock language-text"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre>1
2
3
4
5</pre></div></td><td class="code"><div class="highlight"><pre><span></span>Auto-assigning NUTS sampler...
Initializing NUTS using jitter+adapt_diag...
Multiprocess sampling (2 chains in 2 jobs)
NUTS: [θ]
100%|██████████| 3000/3000 [00:00&lt;00:00, 3695.42it/s]
</pre></div>
</td></tr></table></div><p>The first and second lines tell us that PyMC3 has automatically assigned the <code>NUTS</code> sampler (one inference engine that works very well for continuous variables), and has used a method to initialize that sampler. The third line says that PyMC3 will run two chains in parallel, thus we will get two independent samples from the posterior for the price of one.</p><p>The exact number of chains is computed taking into account the number of processors in your machine; you can change it using the <code>chains</code> argument for the <code>sample</code> function. The next line is telling us which variables are being sampled by which sampler. For this particular case, this line is not adding new information. Because <code>NUTS</code> is used to sample the only variable we have <code>θ</code>. However, this is not always the case as PyMC3 can assign different samplers to different variables. This is done automatically by PyMC3 based on properties of the variables that ensures that the best possible sampler is used for each variable. Users can manually assign samplers using the <code>step</code> argument of the <code>sample</code> function.</p><p>Finally, the last line is a progress bar, with several related metrics indicating how fast the sampler is working, including the number of iterations per second. If you run the code, you will see the progress-bar get updated really fast. Here, we are seeing the last stage when the sampler has finished its work. The numbers are 3000/3000, where the first number is the running sampler number (this starts at 1), and the last is the total number of samples. You will notice that we have asked for 1,000 samples, but PyMC3 is computing 3,000 samples. We have 500 samples per chain to auto-tune the sampling algorithm (<code>NUTS</code>, in this example). This sample will be discarded by default. We also have 1,000 productive draws per-chain, thus a total of 3,000 samples are generated. The tuning phase helps PyMC3 provide a reliable sample from the posterior. We can change the number of tuning steps with the <code>tune</code> argument of the <code>sample</code> function.</p><span id="summarizing-the-posterior" class="anchor-target"></span><h2 class="heading">Summarizing the posterior <a class="header-link" href="index.html#summarizing-the-posterior">#</a></h2><hr>
<p>Generally, the first task we will perform after sampling from the posterior is check what the results look like. The plot_trace function from ArviZ is ideally suited to this task:</p><p><img src="../media/uploads/2019/12/04/figure-21.JPG" alt="Figure 2.1.JPG">
<em>Figure 2.1.JPG</em></p><p>By using <code>az.plot_trace</code>, we get two subplots for each unobserved variable. The only unobserved variable in our model is \(\theta\).</p><p>Notice that <code>y</code> is an observed variable representing the data; we do not need to sample that because we already know those values. Thus, in Figure 2.1, we have two subplots. On the left, we have a <strong>Kernel Density Estimation (KDE)</strong> plot; this is like the smooth version of the histogram. On the right, we get the individual sampled values at each step during the sampling. From the trace plot, we can visually get the plausible values from the posterior. You should compare this result using PyMC3 with those from the previous chapter, which were obtained analytically.</p><p>ArviZ provides several other plots to help interpret the trace, and we will see them in the following pages. We may also want to have a numerical summary of the trace. We can get that using <code>az.summary</code>, which will return a pandas DataFrame:</p><div class="codeblock language-python"><div class="highlight"><pre><span></span><span class="n">az</span><span class="o">.</span><span class="n">summary</span><span class="p">(</span><span class="n">trace</span><span class="p">)</span>
</pre></div>
</div><p><img src="../media/uploads/2019/12/04/selection_052.png" alt="Selection_052.png"></p><p>We get the mean, standard deviation (sd), and 94% HPD interval (hpd 3% and hpd 97%). We can use these numbers to interpret and report the results of a Bayesian inference. The last two metrics are related to diagnosing samples.</p><p>Another way to visually summarize the posterior is to use the <code>plot_posterior</code> function that comes with ArviZ. We have already used this distribution in the previous chapter for a fake posterior. We are going to use it now for a real posterior. By default, <code>plot_posterior</code> shows a histogram for discrete variables and KDEs for continuous variables. We also get the mean of the distribution (we can ask for the median or mode using the <code>point_estimate</code> argument) and the 94% HPD as a black line at the bottom of the plot. Different interval values can be set for the HPD with the <code>credible_interval</code> argument. This type of plot was introduced by John K. Kruschke in his great book <strong>Doing Bayesian Data Analysis</strong>:</p><div class="codeblock language-python"><div class="highlight"><pre><span></span><span class="n">az</span><span class="o">.</span><span class="n">plot_posterior</span><span class="p">(</span><span class="n">trace</span><span class="p">)</span>
</pre></div>
</div><p><img src="../media/uploads/2019/12/04/figure-22.JPG" alt="Figure 2.2.JPG">
<em>Figure 2.2</em></p><span id="posterior-based-decisions" class="anchor-target"></span><h2 class="heading">Posterior-based decisions <a class="header-link" href="index.html#posterior-based-decisions">#</a></h2><hr>
<p>Sometimes, describing the posterior is not enough. Sometimes, we need to make decisions based on our inferences. We have to reduce a continuous estimation to a dichotomous one: yes-no, health-sick, contaminated-safe, and so on. We may need to decide if the coin is fair or not. A fair coin is one with a \(\theta\) value of exactly 0.5. We can compare the value of 0.5 against the HPD interval. In Figure 2.2, we can see that the HPD goes from ≈0.02 to ≈0.71 and hence 0.5 is included in the HPD. According to our posterior, the coin seems to be tail-biased, but we cannot completely rule out the possibility that the coin is fair. If we want a sharper decision, we will need to collect more data to reduce the spread of the posterior or maybe we need to find out how to define a more informative prior.</p><span id="region-of-practical-equivalence-rope-interval" class="anchor-target"></span><h2 class="heading">Region Of Practical Equivalence (ROPE) interval <a class="header-link" href="index.html#region-of-practical-equivalence-rope-interval">#</a></h2><hr>
<p>Strictly speaking, the chance of observing exactly 0.5 (that is, with infinite trailing zeros) is zero. Also, in practice, we generally do not care about exact results, but results within a certain margin. Accordingly, in practice, we can relax the definition of fairness and we can say that a fair coin is one with a value of \(\theta\) around 0.5. For example, we could say that any value in the interval [0.45, 0.55] will be, for our purposes, practically equivalent to 0.5. We call this interval a <strong>Region Of Practical Equivalence (ROPE)</strong>. Once the ROPE is defined, we compare it against the <strong>Highest-Posterior Density (HPD)</strong>. We can get at least three scenarios:</p>
<ul>
<li>The ROPE does not overlap with the HPD; we can say the coin is not fair</li>
<li>The ROPE contains the entire HPD; we can say the coin is fair</li>
<li>The ROPE partially overlaps with HPD; we cannot say the coin is fair or unfair</li>
</ul>
<p>If we choose a ROPE in the interval [0, 1], we will always say we have a fair coin. Notice that we do not need to collect data to perform any type of inference. Of course, this is a trivial, unreasonable, and dishonest choice and probably nobody is going to agree with our ROPE definition. I am just mentioning it to highlight the fact that the definition of the ROPE is context-dependent; there is no auto-magic rule that will fit everyone&#39;s intentions. Decisions are inherently subjective and our mission is to take the most informed possible decisions according to our goals.</p><p>We can use the <code>plot_posterior</code> function to plot the posterior with the HPD interval and the ROPE. The ROPE appears as a semi-transparent thick (green) line:</p><div class="codeblock language-python"><div class="highlight"><pre><span></span><span class="n">az</span><span class="o">.</span><span class="n">plot_posterior</span><span class="p">(</span><span class="n">trace</span><span class="p">,</span> <span class="n">rope</span><span class="o">=</span><span class="p">[</span><span class="mf">0.45</span><span class="p">,</span> <span class="o">.</span><span class="mi">55</span><span class="p">])</span>
</pre></div>
</div><p><img src="../media/uploads/2019/12/04/figure-23.JPG" alt="Figure 2.3.JPG">
<em>Figure 2.3.JPG</em></p><p>Another tool we can use to help us make a decision is to compare the posterior against a reference value. We can do this using <code>plot_posterior</code>. As you can see, we get a vertical (orange) line and the proportion of the posterior above and below our reference value:</p><div class="codeblock language-python"><div class="highlight"><pre><span></span><span class="n">az</span><span class="o">.</span><span class="n">plot_posterior</span><span class="p">(</span><span class="n">trace</span><span class="p">,</span> <span class="n">ref_val</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
</pre></div>
</div><p><img src="../media/uploads/2019/12/04/figure-24.JPG" alt="Figure 2.4.JPG">
<em>Figure 2.4.JPG</em></p><p>In this post we discuss how to build probabilistic models with PyMC3.  To know, how to perform hypothesis testing in a Bayesian framework and the caveats of hypothesis testing, whether in a Bayesian or non-Bayesian setting, we recommend you to read <a href="https://www.packtpub.com/big-data-and-business-intelligence/bayesian-analysis-python-second-edition" rel="nofollow" >Bayesian Analysis with Python</a> by Packt Publishing.</p>

<hr>

<p>Other Tutorials (Sponsors)</p>

<p class="advert">
    This site generously supported by
    <a rel="sponsored noopener" target="_blank"
       href="https://www.datacamp.com/?utm_source=thepythonguru&utm_campaign=thepythonguru_tutorials">
        DataCamp</a>. DataCamp offers online interactive
    <a rel="sponsored noopener" target="_blank" href="https://www.datacamp.com/courses/?utm_source=thepythonguru&utm_campaign=thepythonguru_tutorials">
        Python Tutorials
    </a> for Data Science. Join over a million other learners and get
    started learning Python for data science today!
</p>


    



        <nav aria-label="pagination">
            <ul class="pager">
                
                    <li class="previous">
                        <a href="../top-5-python-frameworks-for-web-development/index.html" title="Top 5 Python frameworks for web development">
                            <span class="fa fa-arrow-left" aria-hidden="true"></span>
                            Top 5 Python frameworks for web develop…
                        </a>
                    </li>
                

                
                    <li class="next">
                        <a href="../python-classes-and-interfaces/index.html" title="Python Classes and Interfaces">
                            Python Classes and Interfaces
                            <span class="fa fa-arrow-right" aria-hidden="true"></span>
                        </a>
                    </li>
                
            </ul>
        </nav>





<hr>



    <div id="disqus_thread">
    <p style="margin-bottom: 22px" class="text-center">
        <a href="index.html#" class=" btn btn-primary comments-holder" onclick="loadDisqus();return false;">View Comments</a>
    </p>
    </div>
    <script>
        var is_disqus_loaded = false;
        function loadDisqus() { // DON'T EDIT BELOW THIS LINE
            is_disqus_loaded = true;
            var d = document, s = d.createElement('script');
            s.src = 'https://thepythonguru.disqus.com/embed.js';
            s.setAttribute('data-timestamp', +new Date());
            (d.head || d.body).appendChild(s);
        }
    </script>
    <noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>







            </div>
        </div>


        <div class="sidebar">
        
            <div class="col-lg-4 col-md-4 col-sm-12">
                

    
        

<div class="well">
    <form action="https://thepythonguru.com/search/">
        <div class="input-group">
            <input type="text" class="form-control" name="query" placeholder="Search here"
                   value="">
            <span class="input-group-btn">
                            <button class="btn btn-default" type="submit">
                                <span class="glyphicon glyphicon-search"></span>
                        </button>
                        </span>
        </div>
    </form>
    <!-- /.input-group -->
</div>

<div class="well" id="myAffix">
    <a href="https://www.datacamp.com/" rel="noopener">
        <img class="center-block" src="../static/wiki/images/filip_ad.png" alt="">
    </a>
</div>



<div class="well">
    <h4>Recent Posts</h4>
    <ul>
        
            <li><a href="../tips-to-become-a-top-gamer/index.html">Tips to Become a Top Gamer</a></li>
        
            <li><a href="../choosing-the-right-database-service-factors-to-consider-for-scalability-security-and-performance/index.html">Choosing the Right Database Service: Factors to Consider for Scalability, Security, and Performance</a></li>
        
            <li><a href="../benefits-of-using-python-for-cyber-security/index.html">Benefits of Using Python for Cyber Security</a></li>
        
            <li><a href="../vue-vs-react-what-are-the-best-js-technologies-in-2023/index.html">Vue VS React: What Are The Best JS Technologies In 2023</a></li>
        
            <li><a href="../why-you-should-choose-python-in-2023/index.html">Why You Should Choose Python in 2023?</a></li>
        

    </ul>
</div>

    

    
        
    


            </div>
        </div>
    </div>



    <hr>

    <!-- Footer -->
    <footer class="text-center tpg-footer" >
        <div class="row">
            <div class="col-lg-12">
                <ul class="tpg-footer-links text-center">
                    <li><a href="../about/index.html">About</a></li>
                    <li><a href="../terms-of-use/index.html">Terms</a></li>
                    <li><a href="../privacy-policy/index.html">Privacy Policy</a></li>
                    <li><a href="../contact-us/index.html">Contact</a></li>
                </ul>
                <hr>
                <p>&copy; 2025 ThePythonGuru.com</p>
            </div>
            <!-- /.col-lg-12 -->
        </div>
        <!-- /.row -->
    </footer>

</div>

<script type="text/javascript" src="../static/CACHE/js/output.1879f88478d8.js"></script>




<script>
    window.cookieconsent.initialise({
        "palette": {
            "popup": {
                "background": "#252e39"
            },
            "button": {
                "background": "#14a7d0"
            }
        },
        "theme": "classic",
        "content": {
            "href": "https://thepythonguru.com/privacy-policy/"
        }
    });
</script>

<script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"></script>

</body>
</html>

